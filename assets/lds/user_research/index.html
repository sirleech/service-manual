<html>
<head>
<title>Learning Design Standard - User Research</title>
</head>
<body>

<h1>Learning Design Standard - User Research</h1>

<p><strong>On this page</strong></p>

  <ul>
  <li> <a href="#revision-history">Revision history</a></li>

  <li> <a href="#using-the-learning-design-standards">Using the Learning Design 
    Standards</a></li>

  <li> <a href="#the-opportunity">The opportunity</a></li>

  <li> <a href="#guidance-for-providers">Guidance for providers</a></li>

  <li> <a href="#guidance-for-agencies">Guidance for agencies</a></li>

  <li> <a href="#setting-the-context">Setting the context</a></li>

  <li> <a href="#jobs-roles-and-skills">Jobs, roles and skills</a></li>

  <li> <a href="#overview-of-user-research">Overview of user research</a></li>

  <li> <a href="#target-audience">Target audience</a></li>

  <li> <a href="#pathways-to-user-research">Pathways to user research</a></li>

  <li> <a href="#qualifications-and-certifications">Qualifications and certifications</a></li>

  <li> <a href="#capabilities-needed-for-user-research">Capabilities needed for 
    user research</a></li>

  <li> <a href="#relevant-sfia-skills">Relevant SFIA skills</a></li>

  <li> <a href="#references">References</a></li>

  <li> <a href="#key-content-areas">Key content areas</a></li>
</ul>

<h2 id="revision-history">Revision history</h2>

<table class="content-table" summary="Table showing the revision history of the Learning Design Standards for 2018. It lists the date, version number, contact person and a short few words about what was changed in each revision.">
<thead>
<tr style="vertical-align: top;">
<th scope="col">Date
</th>
<th scope="col">Version
</th>
<th scope="col">Contact
</th>
<th scope="col">Content
</th></tr>
</thead>
<tbody>
<tr style="vertical-align: top;">
<td><p>22/03/2018</p>
</td>
<td><p>0.3</p>
</td>
<td><p>Namrata Roy Chowdhury</p>
</td>
<td><p>First versioned draft</p>
</td></tr>
<tr style="vertical-align: top;">
<td><p>4/05/2018</p>
</td>
<td><p>0.4</p>
</td>
<td><p>Namrata Roy Chowdhury</p>
</td>
<td><p>First exposure draft</p>
</td></tr>
<tr style="vertical-align: top;">
<td><p>18/06/2018</p>
</td>
<td><p>1</p>
</td>
<td><p>Ross McGuire</p>
</td>
<td><p>Added &#8211; Intellectual property and moral rights &#8211; pg. 5</p>
</td></tr>
<tr style="vertical-align: top;">
<td><p>18/06/20108</p>
</td>
<td><p>1</p>
</td>
<td><p>Ross McGuire</p>
</td>
<td><p>DTA Version created</p>
</td></tr>
</tbody>
</table>

<h2 id="using-the-learning-design-standards">Using the Learning Design Standards</h2>

<p>The Australian Public Service Commission (APSC) has developed Learning Design Standards (LDS) to describe a capability needed by the Australian Public Service (APS) to help with the digital transformation of government services. </p>

<p>The LDS describes the context, business need, target audience, underpinning capabilities and curriculum for these capabilities. It does not prescribe or mandate a specific learning solution or format to build the capability described. That is left open for providers and sellers to design solutions that meet the specific needs of individual agencies.</p>

<p>This document is for:</p>

  <ul><li><strong> Providers and sellers</strong> seeking to work with APS agencies to understand the needs of the APS when developing and marketing products.</li>

  <li><strong> APS agencies</strong> seeking to build capability, to inform their learning &amp; development planning, program development and approaches to market for learning solutions.</li></ul>

<p>All queries relating to this standard should be directed to <a href="mailto:capability@apsc.gov.au">capability@apsc.gov.au</a>.</p>

<h3>Intellectual property and moral rights</h3>

<p>Intellectual property in parts of these materials may be owned by the Skills Framework for the Information Age (SFIA) Foundation.</p>

<p>The Australian Public Service Commission (APSC) holds an extended public sector licence on behalf of all Australian Public Service (APS) agencies covered by the Public Service Act 1999 (PS Act) for the use of SFIA materials. This licence permits certain uses of SFIA materials including the creation and internal distribution of products and services derived from or using significant extracts of SFIA materials. The licence does not extend to commercial use of the materials and does not cover Commonwealth bodies other than agencies under the PS Act.</p>

<p>These materials may only be used by APS agencies in accordance with the terms of the extended public sector licence granted to the APSC. No other uses of these materials are permitted For more information on the APSC SFIA licence contact <a href="mailto:capability@apsc.gov.au">capability@apsc.gov.au</a>.</p>

<p>Third-parties, including commercial entities and non-APS Commonwealth entities 
  wishing to use these materials should contact SFIA via <a href="http://www.sfia-online.org">www.sfia-online.org</a></p>

<h2 id="the-opportunity">The opportunity</h2>

<p>The Australian Government is modernising the way it delivers services to citizens. &#8216;Digital by default&#8217; is the guiding principle. This means many APS agencies will need to engage multidisciplinary teams in the design, development and implementation of digital services as defined in the <a href="https://www.dta.gov.au/standard/">Digital Service Standard</a>. User research has been identified as a key skill that will be in high demand for the APS workforce to transform service delivery.</p>

<h2 id="guidance-for-providers">Guidance for providers</h2>

<h3>Good learning design</h3>

<p>When proposing or developing a solution, it is important to be consistent with contemporary instructional design practices. Adult learning is a continuous process that is not limited to the classroom or formal training activities. Good learning design leverages the ways adults learn all the time through a range of experiences. </p>

<p>The diagram below shows some elements that you could include in a learning program. </p>

<p><strong>Figure 1 - Pathways to learning</strong></p>

<p><img src="images/user-research-1.jpg" alt="Diagram showing pathways to adult learning design for proposing and developing solutions and their key elements. It includes: Training, Self directed learning, Formal education, Blogs, Expos and events, Peer-to-peer, On the job and Networks." border="0" width="533" height="503"/></p>

<h3>Learning environment</h3>

<p>The APS is made up of many different departments and agencies. Each may have their own:</p>

  <ul><li> culture</li>

  <li> business needs</li>

  <li> technical platforms</li>

  <li> geographic dispersion</li>

  <li> existing level of digital capability and maturity</li></ul>

<p>If your learning solution is intended for broad use across the APS you need to consider how it would apply in different contexts. Any digital solutions you develop need to be able to be deployed on a wide range of platforms.</p>

<h3>Standards of compliance</h3>

<p>The APS will require all digital learning solutions to be compatible with the 
  following standards:</p>  
<ul>
  <li> Web content accessibility guidelines version 2.0 AA compliance level</li>
  <li> Australian Signals Directorate (ASD) Information Security Manual Standards</li>
</ul>
<p>The APS recommend that digital learning solutions consider the following standards:</p>
<ul>
  <li> Digital Transformation Agency (DTA) <a href="https://www.dta.gov.au/standard/">Digital 
    Service Standard</a></li>
  <li> <a href="https://www.imsglobal.org/learningdesign/index.html">Learning 
    Design Specification standard</a> </li>
</ul>


<h3>Learning outcome assessment</h3>

<p>Agency requirements for assessment may vary. Formative and/or summative assessment may be offered by the provider and should be specified by the agency when engaging providers.</p>

<p><strong>Formative assessment</strong> - <strong><em>monitors learning</em></strong> and gives ongoing feedback. It is used by facilitators to improve their teaching, and by learners to improve their learning. The purpose is assessment <strong>FOR</strong> learning. Examples of formative assessments are</p>

  <ul><li> observations, conferences, questioning </li>

  <li> drawing concept maps, reflections </li>

  <li> self-evaluations and self-assessments </li></ul>

<p><strong>Summative assessment</strong> - evaluates the level of success or capability at the end of a learning activity, comparing it against some standard or benchmark. The purpose is assessment <strong>OF</strong> learning. Examples of summative assessments are: </p>

  <ul><li> a midterm assessment or end-of-course test </li>

  <li> a final project </li>

  <li> a presentation or report</li></ul>

<h2 id="guidance-for-agencies">Guidance for agencies</h2>

<h3>Customising content</h3>

<p>Agencies may extend, reduce or change the content of this LDS. </p>

<p>Agencies should highlight these changes so that providers can readily adapt their learning solutions to meet your agency needs.</p>

<h2 id="setting-the-context">Setting the context</h2>

<h3>Building the digital capability of the Australian Public Service</h3>

<p><em>The Australian Government is progressing a digital transformation agenda to revolutionise the way it delivers services</em>. Australians are more mobile, more connected and more reliant on technology than ever before<strong>. </strong><a href="https://www.dta.gov.au/what-we-do/">The Digital Transformation Agency (DTA)</a> is leading this transformation in order to improve how the Australian Government delivers services online.</p>

<p><em>As part of the digital transformation agenda, the APSC and the DTA are jointly delivering the Building Digital Capability Program. One of the main activities of this program is the identification of digital capability shortfalls and the definition of learning programs to build capability in those areas</em>.</p>

<h3>The Digital Service Standard</h3>

<p>The Digital Transformation Agency guides government service modernisation through the <a href="https://www.dta.gov.au/what-we-do/">Digital Service Standard</a> (&#8216;the Standard&#8217;). The Standard helps digital teams to build services that are simple, clear and fast.</p>

<p><img src="images/user-research-2.jpg" alt="Diagram describing the Digital Service Standard and its steps to guide teams into building efficient services. It includes: Discovery - Start mapping the broader service landscape, researching the real needs and problems faced by your users, and understanding the policy intent and technology constraints. Alpha - Test out your hypotheses by building prototypes in code to explore different ways you might be able to meet your users' needs. Explore multiple ideas. Do user research to learn which approach works best and iterate your solution as you learn more. Beta - Start building based on the minimum viable product you defined at the end of Alpha. Build this as an accessible and secure service. Allow the public to trial the beta alongside the existing service. Use their feedback to improve the service. Live - Put the team and processes in place to continue operating and improving the service. Phasing out the old services and consolidating existing non?digital channels." border="0" width="673" height="518"/></p>

<h3>The multidisciplinary digital delivery team</h3>

<p>The Digital Service Standard suggests the ideal multidisciplinary team to design, build, operate and iterate a digital service. This team includes core (permanent) roles as well as extended roles that you can bring into the team when needed. People may perform one or many roles, depending on their capability and the workload.</p>

<p><strong>Figure 2 - The digital delivery team</strong></p>

<p><img src="images/user-research-3.jpg" alt="Diagram showing the digital delivery team. The service manager is outside the team and responsible for the digital service. Stakeholders are outside of the team. Core Team is composed of Delivery Manager, Product Manager, User Researcher, Service Designer, Interaction Designer, Content Designer, Performance Analyst, Tester, Technology Lead, Developer. The Extended Team is composed of Ethical Hacker, Web Ops Engineer, Accessibility Diversity Specialist, Business Analyst. The extended team may also include various Subject Matter Experts as required." border="0" width="577" height="583"/></p>

<p>The capabilities defined by the Learning Design Standards relate to the roles 
  in a digital delivery team. An agency will be able to use the LDS to define 
  an effective team that meets their specific agency requirements for digital 
  transformation.</p>

<h2 id="jobs-roles-and-skills">Jobs, roles and skills</h2>

<p>Members of multidisciplinary teams may perform many roles in their jobs. Each role has expectations of skill, behaviors and knowledge. You can verify these through relevant qualifications and certifications.</p>

<p><strong>Figure 3 - Role composition</strong></p>

<p><img src="images/user-research-4.jpg" alt="Diagram showing the role composition and its role in the scope of learning design standards, taking into account experience, skills, and knowledge. These three components are brought together through Experience and are asssured through Qualifications and Certifications." border="0" width="531" height="401"/></p>

<p>This Learning Design Standard only addresses learning outcomes for professional skills and knowledge. A person who has done training also needs to put it into practice. This allows them to gain experience and become effective. Individual agencies will determine how they manage experience.</p>

<p>Providers may wish to provide certifications that verify the learning outcomes specified in this LDS, but these are not mandated. It is up to individual agencies to decide if they want certification.</p>

<p>Individual agencies will define jobs according to their needs. Jobs may involve one role only, though it is becoming more common for multidisciplinary teams to have job fluidity. Members may perform many roles according to their capabilities and the needs of the team.</p>

<h2 id="overview-of-user-research">Overview of user research</h2>

<p>User researcher&#8217;s scope, plan and carry out research activities with users. They support teams in getting a deep understanding of the people that use a service.</p>

<p>User research takes a human-centred approach to design. It uses a variety of methods to drive the design and development process. It helps to create seamless, user-friendly interactions.</p>

<p>User researchers support multidisciplinary teams by:</p>

  <ul><li> planning and undertaking research</li>

  <li> generating new and useful user insights</li>

  <li> contributing to user stories which form a basis to design, build, operate and iterate a digital service. </li></ul>

<h3>User research in the context of user centred design</h3>

<p>User centred design places the needs, behaviours and experience of end users at the heart of the design process. The user research capability described in this learning design standard primarily encompasses the research<strong> </strong>component. Some aspects of the analysis and evaluation components are also included. In a multidisciplinary team, the user researcher will work closely with analysts, designers, developers and testers to ensure their research outcomes are understood and inform continuing research activities.</p>

<p><strong>Figure 4 - User Centred Design process</strong></p>

<p><img src="images/user-research-5.jpg" alt="Figure demonstrating the user centred design process which places the needs, behaviours, and experiences of users at the heart of the design through research, analysis, design and evaluation with anticipated implementation." border="0" width="542" height="264"/></p>

<h2 id="target-audience">Target audience</h2>

<h3>Primary</h3>

<p>Employees who are responsible for providing insights into user experience, needs and behaviour to inform the design or improvement of digital services.</p>

<p>APS employees with academic qualifications in relevant disciples who are seeking to apply and further extend their skills in a digital service delivery team or Australian Government context.</p>

<h3>Secondary</h3>

<p>Employees within a multidisciplinary service delivery team performing related 
  activities to develop and improve user centered digital services.</p>

<h2 id="pathways-to-user-research">Pathways to user research</h2>

<p>Everybody has a different work history and career path. The following are some of the more common fields people may have come from before coming to the current role:</p>

  <ul><li> Project managers</li>

  <li> Business analysts</li>

  <li> Team leaders</li>

  <li> Lead developers</li>

  <li> Development team members</li>

  <li> Product managers</li>

  <li> Customer service roles</li>

  <li> Systems designers</li>

  <li> Digital media</li></ul>

<h2 id="qualifications-and-certifications">Qualifications and certifications</h2>

<p>The following qualifications are relevant to the capability described in this LDS:</p>

  <ul><li> Psychology</li>

  <li> Anthropology</li>

  <li> Cognitive science</li>

  <li> Communications and marketing</li>

  <li> Human computer interaction</li>

  <li> Academic research</li>

  <li> Sociology</li>

  <li> Market research</li></ul>

<h2 id="capabilities-needed-for-user-research">Capabilities needed for user research</h2>

<p>The skills, knowledge and attributes listed below are the minimum needed for someone to be effective in this role. A person undertaking the learning defined by this LDS should have the knowledge and skills described below after finishing the learning. They may need experience of these in a workplace to embed the learning and become effective.</p>

<table class="content-table" summary="Table showing the knowledge, skills and attributes needed to be effective in this role according to the Learning Design standards.">
<thead>
<tr style="vertical-align: top;">
<th scope="col">Knowledge:
</th>
<th scope="col">Skills:
</th>
<th scope="col">Attributes:
</th></tr>
</thead>
<tbody>
<tr style="vertical-align: top;">
<td><p><strong>Organisational Context</strong></p>
  <ul><li> Government frameworks and processes</li>
  <li> DTA digital service standard</li></ul>
<p><strong>Methodologies, procedures and standards</strong></p>
  <ul><li> Research and observation methods</li>
  <li> Analysis and synthesis</li>
  <li> Agile Team roles and responsibilities</li></ul>
<p><strong>Tools</strong></p>
  <ul><li> Collaboration tools and techniques</li></ul>
<p><strong>Theory/theoretical</strong></p>
  <ul><li> Strategic perspective</li></ul>
<p><strong>Principles</strong></p>
  <ul><li> Agile practices &amp; principles</li>
<li> Ethics and privacy</li></ul>
</td>
<td><p><strong>Analysis, synthesis &amp; evaluation</strong></p>
  <ul><li> Findings and insights</li>
  <li> Metrics and measurement</li></ul>
<p><strong>Communication</strong></p>
  <ul><li> Continuous improvement</li>
  <li> Storytelling</li>
  <li> Communicating with influence</li></ul>
<p><strong>Relationships and interpersonal</strong></p>
  <ul><li> Collaboration and planning</li>
  <li> Working effectively in teams</li>
  <li> Listening</li></ul>
<p><strong>Leadership and management</strong></p>
<ul><li> Facilitation</li></ul>
</td>
<td><p><strong>Digital</strong></p>
  <ul><li> Digital by default</li></ul>
<p><strong>Professional</strong></p>
  <ul><li> Analytical mindset</li>
  <li> Awareness of cognitive bias</li>
  <li> Persuasiveness</li>
  <li> Intuition</li></ul>
<p><strong>Personal</strong></p>
  <ul><li> Curiosity</li>
  <li> Empathy</li>
  <li> Emotional intelligence</li>
  <li> Passionate about creating value for users</li>
  <li> Willingness to learn </li>
  <li> Positive / optimistic </li>
  <li> Objectivity</li></ul>
</td></tr>
</tbody>
</table>

<h2 id="relevant-sfia-skills">Relevant SFIA skills</h2>

<p>The <em>Skills Framework for the Information Age</em> (SFIA) is a global standard that defines Digital and other ICT related skills. A person possessing the following SFIA skills at the levels indicated would be capable of performing the role described by this standard.</p>

<table class="content-table" summary="Table lists the relevant SFIA (Skills Framework for the Information Age) level required for aforementioned roles. Each skill code is hyperlinked to the description of that skill from the SFIA website.">
<thead>
<tr style="vertical-align: top;">
<th scope="col">Code
</th>
<th scope="col">Skill
</th>
<th scope="col">Applicable Levels
</th>
<th scope="col">Caveats*
</th></tr>
</thead>
<tbody>
<tr style="vertical-align: top;">
<td><p><a href="https://www.sfia-online.org/en/sfia-7/skills/solution-development-and-implementation/human-factors/user-research">URCH</a></p>
</td>
<td><p>User research</p>
</td>
<td><p>4</p>
</td>
<td><p>-</p>
</td></tr>
<tr style="vertical-align: top;">
<td><p><a href="https://www.sfia-online.org/en/sfia-6/skills/solution-development-and-implementation/human-factors/user-experience-analysis">UNAN</a></p>
</td>
<td><p>User experience analysis</p>
</td>
<td><p>4</p>
</td>
<td><p>-</p>
</td></tr>
<tr style="vertical-align: top;">
<td><p><a href="https://www.sfia-online.org/en/sfia-6/skills/solution-development-and-implementation/human-factors/user-experience-evaluation">USEV</a></p>
</td>
<td><p>User experience evaluation</p>
</td>
<td><p>3</p>
</td>
<td><p>-</p>
</td></tr>
<tr style="vertical-align: top;">
<td><p><a href="https://www.sfia-online.org/en/sfia-6/skills/business-change/business-change-management/business-analysis">BUAN</a></p>
</td>
<td><p>Business analysis</p>
</td>
<td><p>4</p>
</td>
<td><p>-</p>
</td></tr>
</tbody>
</table>

<p>*Caveats are identified components of a SFIA skill that are not explicitly 
  required for the current role. For the purpose of this Learning Design Standard 
  the SFIA description should be read as though the caveated components were not 
  included in the SFIA skill description.</p>

<h2 id="references">References</h2>

  <ul><li> <a href="https://www.dta.gov.au/standard/design-guides/">DTA Guidance to meeting the Digital Service Standard</a></li>

  <li> <a href="https://www.gov.uk/service-manual">UK GDS Service Manual</a></li>

  <li> <a href="https://design.google/">Google Design</a></li>

  <li> <a href="https://www.dta.gov.au/standard/">DTA Digital Service Standard</a></li>

  <li> <a href="https://blog.practicalservicedesign.com/the-difference-between-a-journey-map-and-a-service-blueprint-31a6e24c4a6c">Blog: The difference between a journey map and a service blueprint</a></li>

  <li> <a href="https://www.usertesting.com/blog/2015/07/01/how-to-break-into-the-field-of-ux-research/">Blog: How to Break into the Field of UX Research</a></li>

  <li> <a href="https://www.gov.uk/government/publications/user-researcher-skills-they-need/user-researcher-skills-they-need">UK DDaT User researcher: skills they need</a></li>

  <li> <a href="https://www.interaction-design.org/literature/article/conducting-ethical-user-research">Blog: Conducting Ethical User Research</a></li>

  <li> <a href="http://guides.library.uwa.edu.au/c.php?g=325196&amp;p=2178575">UWA Research Data Management Toolkit: Ethics, privacy, consent and legal issues</a></li></ul>

<h2 id="key-content-areas">Key content areas</h2>

<p>The following table outlines content areas that need to be addressed. </p>

<p>Unit = area of learning. <br />
Topic = Component of area of learning. </p>

<h3>Unit 1. The role of user research in the digital service design context</h3>

<p><strong>Learning objective:</strong> Describe the context and processes of user research</p>

<table class="content-table" summary="Table describes the context and processes of user research with relevant learning objectives and critical content.">
<thead>
<tr style="vertical-align: top;">
<th scope="col">Topic title
</th>
<th scope="col">Topic learning objectives
</th>
<th scope="col">Critical content
</th></tr>
</thead>
<tbody>
<tr style="vertical-align: top;">
<td><p>1.1 Transforming government digital service delivery</p>
</td>
<td><p><strong>Define</strong> the Australian Government context for digital service delivery</p>
  </td>
<td><ol><li> The Australian Government&#8217;s Digital Transformation Agenda</li>
<li> User research in the APS digital transformation of government services</li></ol>
</td></tr>
<tr style="vertical-align: top;">
<td><p>1.2 User research for government services</p>
</td>
<td><p><strong>Describe</strong> the role of user research in meeting the Digital Service Standard </p>
<p><strong>Explain</strong> the importance of understanding all user groups</p>
<p><strong>Conduct</strong> user research</p>
<p><strong>Conduct</strong> user research as a team sport</p>
  </td>
      <td><ol>
          <li> Meeting the Digital Service Standard</li>
          <li> Understanding the users, including: 
            <ul>
              <li> who they are and what they&#8217;re trying to do</li>
              <li> how they&#8217;re trying to do it now</li>
              <li> how their life influences what they do </li>
            </ul>
          </li>
          <li> How to make research inclusive of all users, including: 
            <ul>
              <li> how people with different needs use the service (including 
                people from culturally and linguistically diverse backgrounds)</li>
              <li> refining the design, functionality and content based on different 
                user experiences</li>
              <li> meeting <a href="https://www.gov.uk/service-manual/helping-people-to-use-your-service/making-your-service-accessible-an-introduction#meeting-government-accessibility-requirements">government 
                accessibility requirements</a></li>
            </ul>
          </li>
          <li> Determining what works, including: 
            <ul>
              <li> what issues people face in interacting with the government 
              </li>
              <li> researching how users can use the service to get the right 
                outcome, rather than their preference</li>
              <li> researching the user&#8217;s complete journey and the ways 
                they interact with the service </li>
            </ul>
          </li>
          <li> Service teams working in an agile way, including: 
            <ul>
              <li> updating the teams understanding of users and their needs</li>
              <li> testing new design ideas and features to see if they work well 
                for all users</li>
              <li> recognising problems users are having</li>
            </ul>
          </li>
          <li> How to involve the team, including: 
            <ul>
              <li> team members watching real users interact with the service 
                and discuss</li>
              <li> team members participating in analysis to help agree on the 
                findings and resulting actions</li>
              <li> user researchers working with designers and developers on design 
                decisions and prototypes</li>
            </ul>
          </li>
          <li> Assembling people in research to help make decisions to improve 
            the service
            <ul>
              <li> inviting the team, stakeholders, and people in the organisation 
                who deal with users </li>
              <li> reducing the risk of bias and unchallenged assumptions</li>
              <li> limiting the influence of individual stakeholders</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>1.3 User research overview</p>
</td>
<td><p><strong>Describe</strong> the various applications of user research in the broader business context</p>
  </td>
      <td><ol>
          <li> Applications of user research 
            <ul>
              <li> urban design</li>
              <li> military</li>
              <li> retail and commerce</li>
            </ul>
          </li>
          <li> Definition and purposes of user research </li>
          <li> The user&#8217;s role in product and service design</li>
          <li> What user research is not, what makes it different from market 
            research and stakeholder consultation</li>
          <li> Generative versus evaluative methods of research
            <ul>
              <li> goals</li>
              <li> why it is valuable</li>
              <li> conducting the research</li>
            </ul>
          </li>
        </ol></td>
    </tr>
</tbody>
</table>

<h3 id="unit2">Unit 2. User research protocols and governance</h3>

<p><strong>Learning objective:</strong> Foundational methods for practicing design research.</p>

<table class="content-table" summary="Table showing a breakdown of the foundational methods for practicing design research with relevant learning objectives and critical content.">
<thead>
<tr style="vertical-align: top;">
<th scope="col">Topic title
</th>
<th scope="col">Topic learning objectives
</th>
<th scope="col">Critical content
</th></tr>
</thead>
<tbody>
<tr style="vertical-align: top;">
<td><p>2.1 Privacy</p>
</td>
<td><p><strong>Describe</strong> procedures for handling information securely</p>
  </td>
      <td><ol>
          <li> Data collection, including: 
            <ul>
              <li> handling sensitive data</li>
              <li> ownership</li>
              <li> confidentiality</li>
            </ul>
          </li>
          <li> When to not collect, use or store participants research data, including:
            <ul>
              <li> getting participants consent if collecting, using or storing 
                any personal data </li>
              <li> informing participants if the data would personally identify 
                them</li>
            </ul>
          </li>
          <li> How to get consent from people with disabilities, children and 
            vulnerable adults</li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>2.2 Ethics</p>
</td>
<td><p><strong>Apply</strong> ethical considerations in designing and conducting research</p>
  </td>
      <td><ol>
          <li> What participants should be aware of before the research, including:
            <ul>
              <li> what they are going to be asked</li>
              <li> how their information will be used</li>
              <li> whether there will be observers</li>
              <li> whether the session will be recorded</li>
            </ul>
          </li>
          <li> Risks and benefits</li>
          <li> Justice (for example, research should address questions relevant 
            for the group)</li>
          <li> Available support</li>
          <li> Appropriate behaviour, language, actions and location</li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>2.3 Safety</p>
</td>
<td><p><strong>Maintain</strong> safety when working with participants and their data</p>
  </td>
<td><ol><li> Physical and psychological safety</li>
  <li> Making sure participants data is safe</li>
  <li> Planning research to not waste participants&#8217; time</li>
  <li> Representing participants accurately</li>
<li> Handling sensitive data shared by participants</li></ol>
</td></tr>
<tr style="vertical-align: top;">
<td><p>2.4 Recruitment</p>
</td>
<td><p><strong>Recruit</strong> the right participants for research</p>
  </td>
      <td><ol>
          <li> Avoiding bias in recruitment, including: 
            <ul>
              <li> using a variety of user research activities and recruitment 
                approaches</li>
              <li> including people with disabilities and limited digital and 
                literacy skills</li>
              <li> avoiding over recruiting people with flexible work patterns</li>
              <li> recruiting those who could be considered &#8216;edge cases&#8217;</li>
            </ul>
          </li>
          <li> Things to consider when recruiting participants with disabilities, 
            including:
            <ul>
              <li> their preferred method of contact</li>
              <li> need for any communication support </li>
              <li> use of any assistive technology</li>
              <li> printing paperwork, such as consent forms in a specific format</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>2.5 Incentives</p>
</td>
<td><p><strong>Explain</strong> the things to consider when offering incentives</p>
  </td>
      <td><ol>
          <li> Recognising whether to pay incentives, including: 
            <ul>
              <li> checking the <a href="https://www.nhmrc.gov.au/_files_nhmrc/publications/attachments/e72_national_statement_may_2015_150514_a.pdf">National 
                Statement of Ethical Conduct in Human Research</a> document to 
                help guide decisions </li>
            </ul>
          </li>
          <li> Types of research where incentives may not be appropriate</li>
          <li> If paying incentives, factoring them into the research proposal 
            and budget</li>
          <li> Deciding on the type of incentive to offer, including: 
            <ul>
              <li> using a recruitment agency or recruiting directly</li>
            </ul>
          </li>
          <li> Deciding criteria for incentives
            <ul>
              <li> type of participant</li>
              <li> research session duration</li>
            </ul>
          </li>
          <li> Seeking advice from agencies or organisations on their practices</li>
          <li> Considering expenses to help participants with disabilities who 
            take part in research</li>
          <li> Ensuring cash incentives are handled separately to research activities</li>
        </ol></td>
    </tr>
</tbody>
</table>

<h3>Unit 3. User research in the different design and delivery phases</h3>

<p><strong>Learning objective:</strong> Executing user research throughout the development phase</p>

<table class="content-table" summary="Table showing a breakdown of the phases executing research throughout the development phase and with relevant learning objectives and critical content.">
<thead>
<tr style="vertical-align: top;">
<th scope="col">Topic title
</th>
<th scope="col">Topic learning objectives
</th>
<th scope="col">Critical content
</th></tr>
</thead>
<tbody>
<tr style="vertical-align: top;">
<td><p>3.1 User research in discovery</p>
</td>
<td><p><strong>Describe</strong> the purpose of user research in discovery</p>
<p><strong>Identify</strong> user groups to conduct research with </p>
<p><strong>Select</strong> the user research activities in discovery</p>
<p><strong>Describe</strong> the user research activity outcomes</p>
  </td>
      <td><ol>
          <li> The aim of user research in discovery, including: 
            <ul>
              <li> finding the users problem by observation performing qualitative 
                research to see how users do things and the barriers they face</li>
            </ul>
          </li>
          <li> Who to research with, including 
            <ul>
              <li> range of users, those with disabilities and low digital skills</li>
              <li> people who provide the service or who support the users </li>
            </ul>
          </li>
          <li> Interviewing users in discovery 
            <ul>
              <li> interviewing users to understand the limitations of the service 
              </li>
              <li> how staff explain the complexities</li>
              <li> undocumented workarounds that people use to get things done</li>
            </ul>
          </li>
          <li> Conducting research activities to learn about users in discovery, 
            including: 
            <ul>
              <li><a href="https://designnotes.blog.gov.uk/2016/04/21/how-to-make-a-user-journey-map/">mapping 
                the user journey</a> of people who want to do the service based 
                task </li>
              <li> examining existing data and reviewing research to avoid bias 
                and help team build understanding of the users</li>
            </ul>
          </li>
          <li> Outcomes of researching in discovery, including:
            <ul>
              <li> users&#8217; touchpoints as they try to achieve their goal, 
                (for example, journey maps, service maps or mental models) </li>
              <li> descriptions of different users, (for example, personas)</li>
              <li> sets of needs and task models for different types of users</li>
              <li> insights about users gained from analysing the research</li>
              <li> a list of research gaps of the current research and opportunities 
                for further research</li>
              <li> using profiles combined with real stories from users the team 
                has met</li>
              <li> ongoing research to understand evolving needs</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>3.2 User research in alpha</p>
</td>
<td><p><strong>Describe</strong> the purpose of user research in alpha</p>
<p><strong>Identify</strong> user groups to conduct research with </p>
<p><strong>Select</strong> user research activities in alpha</p>
<p><strong>Describe</strong> the user research activity outcomes</p>
  </td>
      <td><ol>
          <li> The aim of user research in alpha, including: 
            <ul>
              <li> Helping to improve team&#8217;s understanding of the users 
                and their needs by testing a range of design ideas and prototypes</li>
              <li> exploring hypotheses and prototypes</li>
            </ul>
          </li>
          <li> Who to research with, including: 
            <ul>
              <li> range of users, including people with a range of visual, hearing, 
                motor and cognitive impairments</li>
            </ul>
          </li>
          <li> how to do user research in alpha, including: 
            <ul>
              <li> getting rid of prototypes and ideas if they don&#8217;t meet 
                user needs</li>
              <li> task based testing to understand which version is most effective</li>
              <li> testing prototypes with users</li>
              <li> using insights to iterate the design and test again with users</li>
            </ul>
          </li>
          <li> Conducting research activities to learn about users and the design 
            ideas in alpha, including: 
            <ul>
              <li> using interviews and observations to deepen understanding of 
                the users&#8217; lives </li>
              <li> trying out design concepts with likely users to see how they 
                meet user needs</li>
              <li> testing interactive prototypes to explore the usability of 
                different designs</li>
              <li> combine testing the prototype with discovery style interviews 
                to continue understanding user needs </li>
            </ul>
          </li>
          <li> Outcomes of researching in alpha, including:
            <ul>
              <li> a better understanding of the users&#8217; needs, including 
                their support and access requirements</li>
              <li> feedback on how well the designs work for users</li>
              <li> helpful insight into usability issues related to layout, functionality 
                and content</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>3.3 User research in beta</p>
</td>
<td><p><strong>Describe</strong> the purpose of user research in beta.</p>
<p><strong>Select</strong> user research methods for a working beta service</p>
<p><strong>Describe</strong> the user research activity outcomes</p>
  </td>
      <td><ol>
          <li> How to do user research in beta, including: 
            <ol type="a">
              <li> Researching while building the service: 
                <ul>
                  <li> doing research like done in alpha but aiming to refine 
                    a solution for launch</li>
                  <li> task based usability testing with a range of users</li>
                  <li> deciding on hypotheses (design ideas)</li>
                  <li> accessibility testing with people who have access needs</li>
                  <li> commissioning an external accessibility review before putting 
                    the service into a working beta</li>
                </ul>
              </li>
              <li> Researching with users of a working service, including: 
                <ul>
                  <li> adding analytics (including reporting KPIs to the DTA&#8217;s 
                    Performance Dashboard) </li>
                  <li> interviewing and shadowing real users</li>
                  <li> multivariate testing</li>
                  <li> face-to-face and remote usability tests</li>
                  <li> accessibility audit to uncover accessibility issues and 
                    get fixes</li>
                  <li> private or public beta tests of the end-to-end service 
                    and support options with real users</li>
                  <li> web analytics, performance/platform analytics, back-office 
                    data to measure service performance</li>
                  <li> other digital platforms, including smart device apps, retail 
                    shop fronts, and non-digital channels </li>
                  <li> surveys or follow-up interviews for detailed feedback from 
                    service users</li>
                </ul>
              </li>
            </ol>
          </li>
          <li> Outcomes of researching in beta, including: 
            <ul>
              <li> more information about how different kinds of users experience 
                the services</li>
              <li> the usability and accessibility issues to fix</li>
              <li> ways to improve the service</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>3.4 User research in live</p>
</td>
<td><p><strong>Describe</strong> the purpose of user research in live</p>
<p><strong>Select</strong> user groups to conduct research with </p>
<p><strong>Select</strong> user research activities in live</p>
<p><strong>Describe</strong> the user research activity outcomes</p>
  </td>
      <td><ol>
          <li> The aim of user research in live, including: 
            <ul>
              <li> Assessing the experience of using the service and understanding 
                evolving user needs</li>
              <li> testing new features or improvements</li>
              <li> how to do user research in live</li>
            </ul>
          </li>
          <li> Who to research with 
            <ul>
              <li> researching with broad range of users, including those with 
                limited digital access and confidence</li>
              <li> people with a range of visual, hearing, motor and cognitive 
                impairments</li>
              <li> people who use assistive technologies</li>
            </ul>
          </li>
          <li> Conducting research activities in live, including: 
            <ul>
              <li> reviewing web analytics and back-office data to measure service 
                performance</li>
              <li> surveys or follow-up interviews to collect detailed feedback 
                on the service </li>
              <li> interviews and observations to get a deeper understanding of 
                problems users share</li>
              <li> face-to-face and remote usability tests for added or changed 
                features</li>
              <li> multivariate testing</li>
            </ul>
          </li>
          <li> Outcomes of researching in live, including:
            <ul>
              <li> recognising how different kinds of users experience the service</li>
              <li> insights into usability and accessibility issues and how to 
                fix them</li>
            </ul>
          </li>
        </ol></td>
    </tr>
</tbody>
</table>

<h3>Unit 4. Methods and tools of user research</h3>

<p><strong>Learning objective:</strong> Applying common methods and tools.</p>

<table class="content-table" summary="Table showing a breakdown of the application of common methods and tools with relevant learning objectives and critical content.">
<thead>
<tr style="vertical-align: top;">
<th scope="col">Topic title
</th>
<th scope="col">Topic learning objectives
</th>
<th scope="col">Critical content
</th></tr>
</thead>
<tbody>
<tr style="vertical-align: top;">
<td><p>4.1 Selecting the right research method</p>
</td>
<td><p><strong>Define</strong> a technique to help in applying a user research method</p>
<p><strong>Identify</strong> the intended stage and purpose for each method</p>
  </td>
      <td><ol>
          <li> To know when to use which method, use a 3-dimensional framework 
            with the following axes: 
            <ul>
              <li> attitudinal vs behavioural</li>
              <li> qualitative vs quantitative</li>
              <li> context of use</li>
            </ul>
          </li>
          <li> Moderated methods of collecting data, include but are not limited 
            to: 
            <ul>
              <li> experience mapping</li>
              <li> in-depth interviews </li>
              <li> ethnographic field studies</li>
              <li> contextual inquiry</li>
              <li> card Sorting</li>
            </ul>
          </li>
          <li> Unmoderated methods of collecting data, include but are not limited 
            to:
            <ul>
              <li> surveys</li>
              <li> diary and camera studies</li>
              <li> email surveys</li>
              <li> intercept studies</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>4.2 Triangulation in user research</p>
</td>
<td><p><strong>Describe</strong> the value of triangulation in ensuring a stable, solid research design</p>
  </td>
      <td><ol>
          <li> Explain why to triangulate in user research, including:
            <ul>
              <li> using qualitative and quantitative methods in connection with 
                each other</li>
              <li> superseding the limitations of one method with the strengths 
                of another method</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>4.3 Working as a team to find answers to research questions</p>
</td>
<td><p><strong>Recognise</strong> the best time to capture research questions</p>
  </td>
      <td><ol>
          <li> When to capture research questions for a sprint, including: 
            <ul>
              <li> at the start of a new stage of the service design and delivery 
                process</li>
              <li> re-visiting and refining questions as the team learns more 
                about the users and service</li>
              <li> understanding what the team wants to learn and how this changes 
                over time</li>
            </ul>
          </li>
          <li> Reviewing the problem</li>
          <li> Capturing the questions</li>
          <li> Prioritising the questions, including:
            <ul>
              <li> Deciding which questions to focus on in the next sprint</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>4.4 Contextual research and observation</p>
</td>
<td><p><strong>Define</strong> what is contextual research and when to conduct it</p>
<p><strong>Conduct</strong> a contextual research session</p>
  </td>
      <td><ol>
          <li> What is contextual research </li>
          <li> When to do contextual research, including: 
            <ul>
              <li> understanding the problem the service is trying to solve</li>
              <li> using data to see how people use the service in a real-life 
                context </li>
            </ul>
          </li>
          <li> How to do contextual research, including:
            <ul>
              <li> planning the research and designing the visits</li>
              <li> working in pairs</li>
              <li> creating a discussion guide </li>
              <li> doing the research</li>
              <li> using the results to create an experience map showing how people 
                carry out the activity that is being researched</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>4.5 Creating a journey map</p>
</td>
<td><p><strong>Describe</strong> the purpose of a journey map</p>
<p><strong>Create</strong> an experience map</p>
<p><strong>Explain</strong> how journey maps relate to service design maps</p>
  </td>
      <td><ol>
          <li> Using journey maps to sketch the complete journey, including: 
            <ul>
              <li> how users experience the current service and how things do 
                or don&#8217;t work</li>
              <li> interdependencies and paint points </li>
              <li> what users do, think and feel in response to their experience</li>
            </ul>
          </li>
          <li> Creating experience maps with the team, including: 
            <ul>
              <li> preparation and identifying common stages</li>
              <li> building up the experience and sharing the live map with the 
                team</li>
              <li> drawing a detailed map</li>
              <li> sharing a summary map (for example stages and key findings, 
                images and quotes)</li>
            </ul>
          </li>
          <li> List how journey maps can support service designs maps, including:
            <ul>
              <li> Journey maps focus on revealing the end-to-end of the users&#8217; 
                interaction</li>
              <li> Service design maps focus on revealing the linkages between 
                the user&#8217;s experience and the back-end services that enable 
                it </li>
              <li> While journey mapping help surface user experiences, service 
                maps help evidence the reality of the organisation</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>4.6 Conducting pop-up research</p>
</td>
<td><p><strong>Describe</strong> a pop-up research</p>
<p><strong>Explain</strong> pop-up research stages</p>
  </td>
      <td><ol>
          <li> What are the types of pop-up research?</li>
          <li> When pop-up research works best</li>
          <li> How to do pop-up research, including:
            <ul>
              <li> planning the visit and working pairs</li>
              <li> setting up and finding participants</li>
              <li> doing the research and packing up</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>4.7 Taking notes and recording user research sessions</p>
</td>
<td><p><strong>Define</strong> the process of taking notes</p>
<p><strong>Explain</strong> the process of audio, video and screen recording</p>
  </td>
      <td><ol>
          <li> What can you use to document findings</li>
          <li> Privacy and consent</li>
          <li> Anonymous notes and recording, including: 
            <ul>
              <li> inviting an observer as a note-taker</li>
              <li> recording observations rather than personal interpretations</li>
            </ul>
          </li>
          <li> How photos can add value to findings and help the team and stakeholders</li>
          <li> Audio, video and screen recording in research sessions, including:
            <ul>
              <li> recording telephone calls and getting transcripts</li>
              <li> videoing outside labs </li>
              <li> recording participants who use screen readers or interpreters</li>
              <li> using screen-sharing tools to record remote research sessions</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>4.8 Using in-depth interviews</p>
</td>
<td><p><strong>Describe</strong> the process of conducting a complete in-depth interview</p>
  </td>
      <td><ol>
          <li> Planning an in-depth interview, including: 
            <ul>
              <li> creating structure for each topic</li>
              <li> making a discussion guide</li>
              <li> getting a discussion guide peer reviewed</li>
            </ul>
          </li>
          <li> Conducting the interview, including:
            <ul>
              <li> getting informed consent</li>
              <li> focusing on stories and real examples</li>
              <li> avoiding questions that aren&#8217;t based on previous behaviour, 
                for example &#8217;how might you&#8217; or &#8216;how would you&#8217;</li>
              <li> reserving time to ask questions </li>
              <li> explaining what will happen next</li>
              <li> storing collected personal data</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>4.9 Using moderated usability testing</p>
</td>
<td><p><strong>Demonstrate</strong> the process of moderated usability testing</p>
  </td>
      <td><ol>
          <li> Planning moderated usability testing, including: 
            <ul>
              <li> deciding on the prototype to focus on</li>
              <li> recruiting research participants and choosing locations </li>
              <li> arranging interpreters to help participants if needed</li>
              <li> inviting observers and arranging a note taker for each session</li>
            </ul>
          </li>
          <li> Designing the tasks, including: 
            <ul>
              <li> setting test tasks and giving users several small tasks</li>
              <li> creating a discussion guide and an introduction script</li>
              <li> descriptions of test tasks along with instructions</li>
              <li> a planning checklist </li>
            </ul>
          </li>
          <li> Conducting a session, including:
            <ul>
              <li> things to explain participants when introducing tasks</li>
              <li> knowing when it is appropriate to interrupt a participant</li>
              <li> using real data or dummy data </li>
              <li> researching with assistive technologies</li>
            </ul>
          </li>
        </ol></td>
    </tr>
</tbody>
</table>

<h3>Unit 5. Conducting user research</h3>

<p><strong>Learning objective:</strong> Performing user research using appropriate methods in the service design context.</p>

<table class="content-table" summary="Table showing a breakdown of the appropriate methods of performing user research in the service design context with relevant learning objectives and critical content.">
<thead>
<tr style="vertical-align: top;">
<th scope="col">Topic title
</th>
<th scope="col">Topic learning objectives
</th>
<th scope="col">Critical content
</th></tr>
</thead>
<tbody>
<tr style="vertical-align: top;">
<td><p>5.1 Planning user research for the service</p>
</td>
<td><p><strong>Define</strong> the research objectives and determine the approach</p>
  </td>
      <td><ol>
          <li> Planning user research at the start of each development phase, 
            including: 
            <ul>
              <li> updating the plan as you learn more about users</li>
            </ul>
          </li>
          <li> Agreeing on the objectives and deciding the approach to take, including:
            <ul>
              <li> deciding the objectives and approach</li>
              <li> mapping out rounds of research</li>
              <li> involving the team</li>
              <li> agreeing how to feed the findings into the teams agile tools 
              </li>
              <li> ensuring a space for research</li>
              <li> sharing findings with the team and wider stakeholders in events</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>5.2 Developing a round of user research</p>
</td>
<td><p><strong>Construct</strong> a user research plan</p>
  </td>
      <td><ol>
          <li> Planning with designers in the team for different users and stages 
            of the service design and delivery process, including:
            <ul>
              <li> setting research objectives</li>
              <li> finding participants </li>
              <li> planning the session schedule</li>
              <li> arranging recording and note-taking</li>
              <li> practising</li>
              <li> inviting observers who would benefit from observing the sessions 
                (designers, products manager)</li>
              <li> planning consent based on type of research and cohort</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>5.3 Choosing a location for user research</p>
</td>
<td><p><strong>Identify</strong> accessible locations for rounds of user research</p>
  </td>
      <td><ol>
          <li> Choosing the best locations for user research, including:
            <ul>
              <li> meeting rooms, research studios or labs</li>
              <li> participants&#8217; homes or workplaces</li>
              <li> public spaces (pop-up research)</li>
              <li> personal offices (using laptops or phones for remote research)</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>5.4 Finding user research participants</p>
</td>
<td><p><strong>Identify</strong> different kinds of people who need the service</p>
  </td>
      <td><ol>
          <li> Specifying target groups</li>
          <li> How to outline the participant criteria 
            <ul>
              <li> using existing research and service data &#8211; behaviors, 
                attitudes and motivational traits.</li>
            </ul>
          </li>
          <li> Factors to consider while recruiting 
            <ul>
              <li> age, gender, culturally and linguistically diverse backgrounds 
                and access to documentation or systems</li>
            </ul>
          </li>
          <li> Finding participants for research
            <ul>
              <li> using a research recruitment agency and inviting existing users</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>5.5 Writing a recruitment brief</p>
</td>
<td><p><strong>Create</strong> instructions for recruiting participants</p>
  </td>
      <td><ol>
          <li> Listing the contents of a recruitment brief, including: 
            <ul>
              <li> research dates, including times and length of each session 
              </li>
              <li> research location/s</li>
              <li> the number of participants to recruit (including sample sizes)</li>
              <li> a description of the types of people to recruit (referred as 
                recruitment criteria)</li>
              <li> incentives (see <a href="#unit2">unit 2</a>)</li>
            </ul>
          </li>
          <li> How to review a screener based on the recruitment criteria, including:
            <ul>
              <li> ensuring the screener matches the points included in the brief</li>
              <li> requesting standard questions that exclude people likely to 
                be recruited</li>
            </ul>
          </li>
        </ol></td>
    </tr>
</tbody>
</table>

<h3>Unit 6. Analysing and presenting user research findings</h3>

<p><strong>Learning objective:</strong> Sharing user research needs to decision makers and stakeholders.</p>

<table class="content-table" summary="Table showing components to sharing user research needs to decision makers and stakeholders with relevant learning objectives and critical content.">
<thead>
<tr style="vertical-align: top;">
<th scope="col">Topic title
</th>
<th scope="col">Topic learning objectives
</th>
<th scope="col">Critical content
</th></tr>
</thead>
<tbody>
<tr style="vertical-align: top;">
<td><p>6.1 Analysing a user research session</p>
</td>
<td><p><strong>Filter</strong>, organise and interpret data to produce useful insights</p>
  </td>
      <td><ol>
          <li> How to plan an analysis session, including: 
            <ul>
              <li> inviting the people who observed the research to take part 
                in the analysis to reduce the risk of researcher bias</li>
              <li> deciding the next plan of action as a group</li>
              <li> determining how much time to spend on analysis and research</li>
            </ul>
          </li>
          <li> Applying a process to gather observations quickly and easily</li>
          <li> Steps to extract observations and create themes, for example: 
            <ul>
              <li> common topics, such as identity and delivery</li>
              <li> common user behaviors</li>
            </ul>
          </li>
          <li> determining findings 
            <ul>
              <li> reviewing the notes in each group to determine the observations</li>
              <li> writing findings as short statements that summarise what has 
                been learned</li>
            </ul>
          </li>
          <li> using findings to make decisions or new research plans, including: 
            <ul>
              <li> new design ideas, things to change in a prototype and test 
                in research </li>
              <li> new user stories to add to the backlog</li>
              <li> strategic insights to develop user needs or service roadmap</li>
            </ul>
          </li>
        </ol></td>
    </tr>
<tr style="vertical-align: top;">
<td><p>6.2 Sharing the findings</p>
</td>
<td><p><strong>Present</strong> user research findings</p>
  </td>
      <td><ol>
          <li> Depending upon how the research is carried out, sharing it with: 
            <ul>
              <li> stakeholders</li>
              <li> other researchers</li>
              <li> service teams</li>
              <li> users and members of the public</li>
            </ul>
          </li>
          <li> Sharing research findings, including: 
            <ul>
              <li> presenting findings at showcases or research share backs</li>
              <li> updating the research wall </li>
              <li> presenting videos of the research</li>
              <li> creating posters with quotes from participants</li>
              <li> blogging on a department website</li>
            </ul>
          </li>
          <li> Presenting findings, using slide decks or similar
            <ul>
              <li> slide decks can be shared and understood easily by people</li>
            </ul>
          </li>
        </ol></td>
    </tr>
</tbody>
</table>
</body>
</html>
